{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae6b039-39cb-416c-99fb-22879b357a0d",
   "metadata": {},
   "source": [
    "<center><b><font size=6>Data Pre-Processing <b><center>\n",
    "\n",
    "<center><font size=5>    Preprocessing and Normalization<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e0527f-9d17-4154-a300-e138bf8e5ad7",
   "metadata": {},
   "source": [
    "\n",
    "The analysis was performed for different repetition IDs, each corresponding to a separate dataset. \n",
    "These datasets were acquired locally on the PC, with one dataset for each repetition ID.\n",
    "\n",
    "The preprocessing steps involve:\n",
    "1. Cleaning the data\n",
    "2. Filtering the data\n",
    "3. Identifying the relevant TCP ports\n",
    "4. Grouping the data\n",
    "5. Normalization\n",
    "\n",
    "Finally, all preprocessed datasets corresponding to different repetition IDs are concatenated into a single DataFrame, \n",
    "which will be used for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5974db73-8726-4bd3-9b7c-2929196cc4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "507e8eb8-47a4-445d-b3e1-1f2b9517dde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tcp_stream_analysis(file_names):\n",
    "    \"\"\"\n",
    "    Objectives:\n",
    "        Step 1: Integrating the features: tcp_srcport and tcp_dstport\n",
    "        Step 2: Remove columns with source and destination ip addresses\n",
    "        Step 3: Add new features / Remove unused features\n",
    "        Step 4: Drop the samples with NaN or infinit values\n",
    "        Step 5: Reduce the size of dataset by taking the mean value of the features in each group <borowser> <Website> <query> <repetition_id>\n",
    "\n",
    "        Parameters:\n",
    "        - file_names: A list of the csv file names in this format [\"Merged_TCP_Stream_Analysis_<i>.csv\"]. for i being the repetition id of the collected dataset\n",
    "\n",
    "        Returns:\n",
    "        - final_df: pandas.DataFrame, the DataFrame with standardized numerical columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the function to identify tcp_port\n",
    "    def identify_tcp_port(row):\n",
    "        if int(row['tcp_srcport_mode']) not in [443, 80]:\n",
    "            return row['tcp_srcport_mode']\n",
    "        elif int(row['tcp_dstport_mode']) not in [443, 80]:\n",
    "            return row['tcp_dstport_mode']\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    # Initialize an empty list to store DataFrames\n",
    "    dfs = []\n",
    "\n",
    "    # Loop through each file name\n",
    "    for file_name in file_names:\n",
    "        # Load the Dataset\n",
    "        df = pd.read_csv(file_name).dropna().reset_index(drop=True)\n",
    "        \n",
    "        ## (Step 1) ##\n",
    "        #Drop samples where src-port equals dst-port\n",
    "        filtered_df = df[df['tcp_srcport_mode'] != df['tcp_dstport_mode']].copy()\n",
    "\n",
    "        # Create the tcp_port column based on the given conditions\n",
    "        filtered_df.loc[:, 'tcp_port'] = filtered_df.apply(identify_tcp_port, axis=1)\n",
    "\n",
    "        # Drop rows where tcp_port is None (cases where both ports are 443 or 80)\n",
    "        filtered_df = filtered_df.dropna(subset=['tcp_port'])\n",
    "\n",
    "        # Remove the columns 'tcp_srcport_mode' and 'tcp_dstport_mode'\n",
    "        filtered_df.drop(columns=['tcp_srcport_mode', 'tcp_dstport_mode'], inplace=True)\n",
    "        \n",
    "        ## (Step 2) ##\n",
    "        # Remove columns 'ip_src_mode' and 'ip_dst_mode'\n",
    "        if 'ip_src_mode' in filtered_df.columns or 'ip_dst_mode' in filtered_df.columns:\n",
    "            filtered_df.drop(columns=['ip_src_mode', 'ip_dst_mode'], errors='ignore', inplace=True)\n",
    "\n",
    "        ## (Step 3) ## \n",
    "        #Count the number of streams for each combination of <browser>, <website>, and <query>\n",
    "        stream_counts = filtered_df.groupby(['browser', 'website', 'query']).size().reset_index(name='stream_count')\n",
    "\n",
    "        # Merge the counts back into the original DataFrame\n",
    "        filtered_df = pd.merge(filtered_df, stream_counts, on=['browser', 'website', 'query'], how='left')\n",
    "\n",
    "        # Remove the column 'tcp.stream'\n",
    "        if 'tcp.stream' in filtered_df.columns:\n",
    "            filtered_df.drop(columns=['tcp.stream'], inplace=True)\n",
    "\n",
    "        # Remove the column 'unique_tcp_flags'\n",
    "        if 'unique_tcp_flags' in filtered_df.columns:\n",
    "            filtered_df.drop(columns=['unique_tcp_flags'], inplace=True)\n",
    "            \n",
    "        ## (Step4) ##\n",
    "        # Handle NaN and infinity values\n",
    "        filtered_df = filtered_df.replace([np.inf, -np.inf], np.nan).dropna().reset_index(drop=True)\n",
    "\n",
    "        ## (Step 5) ##\n",
    "        #Group by 'browser', 'website', 'query' and calculate the mean of all features\n",
    "        grouped_means = filtered_df.groupby(['browser', 'website', 'query', 'repetition_id']).mean().reset_index()\n",
    "\n",
    "        \n",
    "        # Append the result to the list\n",
    "        dfs.append(grouped_means)\n",
    "\n",
    "    # Concatenate all DataFrames in the list into a single DataFrame\n",
    "    final_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def standardize_dataframe(df, numerical_cols):\n",
    "    \"\"\"\n",
    "    Standardizes the specified numerical columns in the given DataFrame after dropping rows with NaN or infinite values.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame, the input DataFrame.\n",
    "    - numerical_cols: list of str, column names to be standardized.\n",
    "    - output_file: str, the name of the file where the standardized DataFrame will be saved.\n",
    "    \n",
    "    Returns:\n",
    "    - final_df: pandas.DataFrame, the DataFrame with standardized numerical columns.\n",
    "    \"\"\"\n",
    "    # Drop rows with NaN or infinite values\n",
    "    df_cleaned = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    \n",
    "    # Separate the numerical and non-numerical columns\n",
    "    non_numerical_cols = df_cleaned.columns.difference(numerical_cols)\n",
    "    \n",
    "    # Standardize the numerical columns\n",
    "    scaler = StandardScaler()\n",
    "    standardized_data = scaler.fit_transform(df_cleaned[numerical_cols])\n",
    "    \n",
    "    # Create a DataFrame with the standardized data\n",
    "    standardized_df = pd.DataFrame(standardized_data, columns=numerical_cols)\n",
    "    \n",
    "    # Add the non-numerical columns back to the DataFrame\n",
    "    final_df = pd.concat([df_cleaned[non_numerical_cols], standardized_df], axis=1)\n",
    "    \n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bfce8eb-9915-4781-883f-87d110ef6ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Process and label the dataset\n",
    "file_names = [\"Merged_TCP_Stream_Analysis_50.csv\", \"Merged_TCP_Stream_Analysis_60.csv\", \"Merged_TCP_Stream_Analysis_70.csv\", \"Merged_TCP_Stream_Analysis_80.csv\", \"Merged_TCP_Stream_Analysis_90.csv\", \"Merged_TCP_Stream_Analysis_100.csv\"]\n",
    "df = process_tcp_stream_analysis(file_names)\n",
    "\n",
    "# Save the grouped means dataframe to a CSV file\n",
    "df.to_csv('df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1647767a-4255-4e57-af23-b605b16632a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting numerical columns for standardization\n",
    "numerical_cols = ['frame_len_mean', 'frame_len_std', 'tcp_len_mean', 'tcp_len_std',\n",
    "                  'tcp_window_size_value_mean', 'tcp_window_size_value_std', 'tcp_seq_mean', \n",
    "                  'tcp_seq_std', 'ip_ttl_mean', 'ip_ttl_std', 'tcp_ack_mean', 'tcp_ack_std', \n",
    "                  'packet_count', 'tcp_port', 'stream_count']\n",
    "\n",
    "# Selecting non-numerical columns to keep\n",
    "non_numerical_cols = ['browser', 'website', 'query', 'repetition_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6513843b-f840-4a25-a478-b7d65eaec354",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the data. \n",
    "#You can select a specific part of the dataset to normalize and use. \n",
    "df_standard = standardize_dataframe(df, numerical_cols)\n",
    "#df_standard = standardize_dataframe(df.loc[df['repetition_id'] == 60], numerical_cols)\n",
    "\n",
    "# Reorder the columns\n",
    "ordered_columns = ['browser', 'website', 'query', 'repetition_id'] + [col for col in df_standard.columns if col not in ['browser', 'website', 'query', 'repetition_id']]\n",
    "df_standard = df_standard[ordered_columns]\n",
    "\n",
    "# Save the grouped means dataframe to a CSV file\n",
    "df_standard.to_csv('df_standard.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da75932b-8faa-41c7-9964-eda6d388fcbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
